{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrICuL+iTJwjNEJV9nP0K9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrMaciejKowalski/BigData2022-actors/blob/pobieranie_zdj%C4%99%C4%87/pobieranie_zdj%C4%99%C4%87_z_URL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przed uruchomieniem trzeba utworzyć folder \"ImgData\" w MyDrive\n",
        "\n"
      ],
      "metadata": {
        "id": "PrZUQucODnQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "3jvD4dUeSPFN",
        "outputId": "8f343393-dcb1-462b-9c2a-ffd47798a98f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PiotrMaciejKowalski/BigData2022-actors.git\n",
        "!mv /content/BigData2022-actors/* .\n",
        "!mv /content/BigData2022-actors/.* .\n",
        "!rmdir /content/BigData2022-actors/"
      ],
      "metadata": {
        "id": "TJ2XniTm_Imu",
        "outputId": "b18f22ec-3c8b-420c-e078-d2267f1809bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BigData2022-actors'...\n",
            "remote: Enumerating objects: 1665, done.\u001b[K\n",
            "remote: Counting objects: 100% (443/443), done.\u001b[K\n",
            "remote: Compressing objects: 100% (219/219), done.\u001b[K\n",
            "remote: Total 1665 (delta 326), reused 306 (delta 224), pack-reused 1222\u001b[K\n",
            "Receiving objects: 100% (1665/1665), 6.04 MiB | 17.87 MiB/s, done.\n",
            "Resolving deltas: 100% (1014/1014), done.\n",
            "mv: cannot move '/content/BigData2022-actors/.' to './.': Device or resource busy\n",
            "mv: cannot move '/content/BigData2022-actors/..' to './..': Device or resource busy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x setup_sparka.sh\n",
        "!./setup_sparka.sh"
      ],
      "metadata": {
        "id": "g1jJlgp0_Mc1",
        "outputId": "2e37bde3-0bd3-41c1-ff7a-0a5371dc88cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=43e1430d2c787bd02c0b304bb7f49169f82d9b681401527d58af067c5908b8c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
            "--2023-01-19 16:04:37--  https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop2.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 274099817 (261M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.3.1-bin-hadoop2.tgz’\n",
            "\n",
            "spark-3.3.1-bin-had 100%[===================>] 261.40M   276MB/s    in 0.9s    \n",
            "\n",
            "2023-01-19 16:04:49 (276 MB/s) - ‘spark-3.3.1-bin-hadoop2.tgz’ saved [274099817/274099817]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8Vr3rumQ_t9i",
        "outputId": "9e0753c6-c423-4b16-e8d5-d734ad06f925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "import requests\n",
        "import numpy as np\n",
        "import cv2\n",
        "from lib.pyspark_init import create_spark_context"
      ],
      "metadata": {
        "id": "0pDRD8D-QNAc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = create_spark_context()"
      ],
      "metadata": {
        "id": "0CA-6YyzR1Hw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wczytuje obrazy i zapisuje\n",
        "def save_download(url, file_name):\n",
        "    file_name=file_name+'.jpg'\n",
        "    response = requests.get(url)\n",
        "    with open(file_name, \"wb\") as f:\n",
        "      f.write(response.content)\n",
        "    cv2.imwrite('/content/gdrive/MyDrive/bigdataaktorzy/ImgData/'+file_name, cv2.imread('/content/'+file_name))"
      ],
      "metadata": {
        "id": "6rM0Gak9EE7j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_save_download(dataframe, num_col, num_namecol):\n",
        "  for i in range(dataframe.count()):\n",
        "    save_download(dataframe.collect()[i][num_col], str(dataframe.collect()[i][num_namecol]))"
      ],
      "metadata": {
        "id": "HGoNn99mGaWf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test:"
      ],
      "metadata": {
        "id": "aTfThpRkG1D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = [(\"Lucas\",\"https://images.unsplash.com/photo-1508921912186-1d1a45ebb3c1?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxzZWFyY2h8Mnx8cGhvdG98ZW58MHx8MHx8&w=1000&q=80\",\"Smith\",\"36636\",\"M\",3000),\n",
        "    (\"Elijah\",\"https://www.paperlessmovement.com/wp-content/uploads/2019/09/o2dvsv2pnhe.jpg\",\"\",\"40288\",\"M\",4000),\n",
        "    (\"Emma\",\"https://mymodernmet.com/wp/wp-content/uploads/2019/12/photos-of-indonesia-rarindra-prakarsa-4.jpg\",\"Williams\",\"42114\",\"F\",4000),\n",
        "    (\"Sophia\",\"https://live-production.wcms.abc-cdn.net.au/50749be1153e1907d7e1208fc96432f8?impolicy=wcms_crop_resize&cropH=844&cropW=1500&xPos=0&yPos=0&width=862&height=485\",\"Jones\",\"39192\",\"F\",4000),\n",
        "    (\"Mia\",\"https://media.wired.com/photos/62ccbecc4847c5414f1e3dc9/3:2/w_1280%2Cc_limit/Light-Photo-Video-Like-a-Pro-Gear-GettyImages-142009824.jpg\",\"Brown\",\"\",\"F\",-1)\n",
        "  ]\n",
        "\n",
        "schema = StructType([ \\\n",
        "    StructField(\"name\",StringType(),True), \\\n",
        "    StructField(\"url\",StringType(),True), \\\n",
        "    StructField(\"lastname\",StringType(),True), \\\n",
        "    StructField(\"id\", StringType(), True), \\\n",
        "    StructField(\"gender\", StringType(), True), \\\n",
        "    StructField(\"salary\", IntegerType(), True) \\\n",
        "  ])\n",
        " \n",
        "df = spark.createDataFrame(data=dataframe,schema=schema)"
      ],
      "metadata": {
        "id": "gB-0gIYCQy2H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_save_download(df, 1, 0)"
      ],
      "metadata": {
        "id": "PhCcri8KHBXM"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}