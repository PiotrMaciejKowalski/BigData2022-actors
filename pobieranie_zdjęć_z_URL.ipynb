{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiuW/ybY0X6cfaoiHqqeWI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrMaciejKowalski/BigData2022-actors/blob/pobieranie_zdj%C4%99%C4%87/pobieranie_zdj%C4%99%C4%87_z_URL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przed uruchomieniem trzeba utworzyć folder \"ImgData\" w MyDrive\n",
        "\n"
      ],
      "metadata": {
        "id": "PrZUQucODnQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j\n",
        "!pip install -q findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop2.tgz\n",
        "!tar xf spark-3.3.1-bin-hadoop2.tgz\n",
        "import pyspark\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "import pyspark.sql.types as T\n",
        "from pyspark.sql.functions import split, col, monotonically_increasing_id, when\n",
        "from pyspark.sql.types import StructType, StringType, IntegerType, BooleanType, FloatType, TimestampType, DateType, ArrayType, MapType, StructField\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop2\"\n",
        "spark=SparkSession.builder.appName('Colab').getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pDRD8D-QNAc",
        "outputId": "d25ceb10-7035-4df6-c7fb-ecc0e4a68103"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 42 kB/s \n",
            "\u001b[?25hCollecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 63.9 MB/s \n",
            "\u001b[?25h  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 16.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=067d402c3852601c38be53753e23227bc5e1116c80df9fee1458a5d48394929f\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
            "--2022-12-18 16:20:54--  https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop2.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 274099817 (261M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.3.1-bin-hadoop2.tgz’\n",
            "\n",
            "spark-3.3.1-bin-had 100%[===================>] 261.40M   215MB/s    in 1.2s    \n",
            "\n",
            "2022-12-18 16:20:56 (215 MB/s) - ‘spark-3.3.1-bin-hadoop2.tgz’ saved [274099817/274099817]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Vr3rumQ_t9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75653ab6-413c-4dfe-8036-8bb129aaa7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8JQAoZzHAEoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4b0338-cd0e-4de6-effe-0fbb915e3cdf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wczytuje obrazy i zapisuje\n",
        "def save_download(url, file_name):\n",
        "    file_name=file_name+'.jpg'\n",
        "    response = requests.get(url)\n",
        "    with open(file_name, \"wb\") as f:\n",
        "      f.write(response.content)\n",
        "    cv2.imwrite('/content/drive/MyDrive/ImgData/'+file_name, cv2.imread('/content/'+file_name))"
      ],
      "metadata": {
        "id": "6rM0Gak9EE7j"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_save_download(dataframe, num_col, num_namecol):\n",
        "  for i in range(dataframe.count()):\n",
        "    save_download(dataframe.collect()[i][num_col], str(dataframe.collect()[i][num_namecol]))"
      ],
      "metadata": {
        "id": "HGoNn99mGaWf"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test:"
      ],
      "metadata": {
        "id": "aTfThpRkG1D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = [(\"Lucas\",\"https://images.unsplash.com/photo-1508921912186-1d1a45ebb3c1?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxzZWFyY2h8Mnx8cGhvdG98ZW58MHx8MHx8&w=1000&q=80\",\"Smith\",\"36636\",\"M\",3000),\n",
        "    (\"Elijah\",\"https://www.paperlessmovement.com/wp-content/uploads/2019/09/o2dvsv2pnhe.jpg\",\"\",\"40288\",\"M\",4000),\n",
        "    (\"Emma\",\"https://mymodernmet.com/wp/wp-content/uploads/2019/12/photos-of-indonesia-rarindra-prakarsa-4.jpg\",\"Williams\",\"42114\",\"F\",4000),\n",
        "    (\"Sophia\",\"https://live-production.wcms.abc-cdn.net.au/50749be1153e1907d7e1208fc96432f8?impolicy=wcms_crop_resize&cropH=844&cropW=1500&xPos=0&yPos=0&width=862&height=485\",\"Jones\",\"39192\",\"F\",4000),\n",
        "    (\"Mia\",\"https://media.wired.com/photos/62ccbecc4847c5414f1e3dc9/3:2/w_1280%2Cc_limit/Light-Photo-Video-Like-a-Pro-Gear-GettyImages-142009824.jpg\",\"Brown\",\"\",\"F\",-1)\n",
        "  ]\n",
        "\n",
        "schema = StructType([ \\\n",
        "    StructField(\"name\",StringType(),True), \\\n",
        "    StructField(\"url\",StringType(),True), \\\n",
        "    StructField(\"lastname\",StringType(),True), \\\n",
        "    StructField(\"id\", StringType(), True), \\\n",
        "    StructField(\"gender\", StringType(), True), \\\n",
        "    StructField(\"salary\", IntegerType(), True) \\\n",
        "  ])\n",
        " \n",
        "df = spark.createDataFrame(data=dataframe,schema=schema)"
      ],
      "metadata": {
        "id": "gB-0gIYCQy2H"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_save_download(df, 1, 0)"
      ],
      "metadata": {
        "id": "PhCcri8KHBXM"
      },
      "execution_count": 64,
      "outputs": []
    }
  ]
}